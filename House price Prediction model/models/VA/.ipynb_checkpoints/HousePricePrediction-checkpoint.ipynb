{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import timedelta\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def arima_model(series, data_split, params, future_periods, log):\n",
    "    \n",
    "    # log transformation of data if user selects log as true\n",
    "    if log == True:\n",
    "        series_dates = series.index\n",
    "        series = pd.Series(np.log(series), index=series.index)\n",
    "       \n",
    "    # create training and testing data sets based on user split fraction\n",
    "    size = int(len(series) * data_split)\n",
    "    train, test = series[0:size], series[size:len(series)]\n",
    "    history = [val for val in train]\n",
    "    predictions = []\n",
    "\n",
    "    # creates a rolling forecast by testing one value from the test set, and then add that test value\n",
    "    # to the model training, followed by testing the next test value in the series\n",
    "    for t in range(len(test)):\n",
    "        model = ARIMA(history, order=(params[0], params[1], params[2]))\n",
    "        model_fit = model.fit(disp=0)\n",
    "        output = model_fit.forecast()\n",
    "        yhat = output[0]\n",
    "        predictions.append(yhat[0])\n",
    "        obs = test[t]\n",
    "        history.append(obs)\n",
    "    \n",
    "    # forecasts future periods past the input testing series based on user input\n",
    "    future_forecast = model_fit.forecast(future_periods)[0]\n",
    "    future_dates = [test.index[-1]+timedelta(i*365/12) for i in range(1, future_periods+1)]\n",
    "    test_dates = test.index\n",
    "    \n",
    "    # if the data was originally log transformed, the inverse transformation is performed\n",
    "    if log == True:\n",
    "        predictions = np.exp(predictions)\n",
    "        test = pd.Series(np.exp(test), index=test_dates)\n",
    "        future_forecast = np.exp(future_forecast)\n",
    "    \n",
    "    # creates pandas series with datetime index for the predictions and forecast values\n",
    "    forecast = pd.Series(future_forecast, index=future_dates)\n",
    "    predictions = pd.Series(predictions, index=test_dates)\n",
    "    \n",
    "    # generates plots to compare the predictions for out-of-sample data to the actual test values\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    myFmt = mdates.DateFormatter('%m%/%y')\n",
    "    ax.xaxis.set_major_formatter(myFmt)\n",
    "    plt.plot(predictions, c='red')\n",
    "    plt.plot(test)\n",
    "    plt.show()\n",
    "    \n",
    "    # calculates root mean squared errors (RMSEs) for the out-of-sample predictions\n",
    "    error = np.sqrt(mean_squared_error(predictions, test))\n",
    "    print('Test RMSE: %.3f' % error)\n",
    "    \n",
    "    return predictions, test, future_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_series, look_back, split_frac, transforms):\n",
    "    \n",
    "    # log transforming that data, if necessary\n",
    "    if transforms[0] == True:\n",
    "        dates = data_series.index\n",
    "        data_series = pd.Series(np.log(data_series), index=dates)\n",
    "    \n",
    "    # differencing data, if necessary\n",
    "    if transforms[1] == True:\n",
    "        dates = data_series.index\n",
    "        data_series = pd.Series(data_series - data_series.shift(1), index=dates).dropna()\n",
    "\n",
    "    # scaling values between 0 and 1\n",
    "    dates = data_series.index\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data_series.values.reshape(-1, 1))\n",
    "    data_series = pd.Series(scaled_data[:, 0], index=dates)\n",
    "    \n",
    "    # creating targets and features by shifting values by 'i' number of time periods\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(look_back+1):\n",
    "        label = ''.join(['t-', str(i)])\n",
    "        df[label] = data_series.shift(i)\n",
    "    df = df.dropna()\n",
    "    print(df.tail())\n",
    "    \n",
    "    # splitting data into train and test sets\n",
    "    size = int(split_frac*df.shape[0])\n",
    "    train = df[:size]\n",
    "    test = df[size:]\n",
    "    \n",
    "    # creating target and features for training set\n",
    "    X_train = train.iloc[:, 1:].values\n",
    "    y_train = train.iloc[:, 0].values\n",
    "    train_dates = train.index\n",
    "    \n",
    "    # creating target and features for test set\n",
    "    X_test = test.iloc[:, 1:].values\n",
    "    y_test = test.iloc[:, 0].values\n",
    "    test_dates = test.index\n",
    "    \n",
    "    # reshaping data into 3 dimensions for modeling with the LSTM neural net\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, look_back))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, look_back))\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, train_dates, test_dates, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transforms(train_predict, y_train, test_predict, y_test, data_series, train_dates, test_dates, scaler):\n",
    "    \n",
    "    # inverse 0 to 1 scaling\n",
    "    train_predict = pd.Series(scaler.inverse_transform(train_predict.reshape(-1,1))[:,0], index=train_dates)\n",
    "    y_train = pd.Series(scaler.inverse_transform(y_train.reshape(-1, 1))[:,0], index=train_dates)\n",
    "\n",
    "    test_predict = pd.Series(scaler.inverse_transform(test_predict.reshape(-1, 1))[:,0], index=test_dates)\n",
    "    y_test = pd.Series(scaler.inverse_transform(y_test.reshape(-1, 1))[:,0], index=test_dates)\n",
    "    \n",
    "    # reversing differencing if log transformed as well\n",
    "    if (transforms[1] == True) & (transforms[0] == True):\n",
    "        train_predict = pd.Series(train_predict + np.log(data_series.shift(1)), index=train_dates).dropna()\n",
    "        y_train = pd.Series(y_train + np.log(data_series.shift(1)), index=train_dates).dropna()\n",
    "\n",
    "        test_predict = pd.Series(test_predict + np.log(data_series.shift(1)), index=test_dates).dropna()\n",
    "        y_test = pd.Series(y_test + np.log(data_series.shift(1)), index=test_dates).dropna()\n",
    "    \n",
    "    # reversing differencing if no log transform\n",
    "    elif transforms[1] == True:\n",
    "        train_predict = pd.Series(train_predict + data_series.shift(1), index=train_dates).dropna()\n",
    "        y_train = pd.Series(y_train + data_series.shift(1), index=train_dates).dropna()\n",
    "\n",
    "        test_predict = pd.Series(test_predict + data_series.shift(1), index=test_dates).dropna()\n",
    "        y_test = pd.Series(y_test + data_series.shift(1), index=test_dates).dropna()\n",
    "      \n",
    "    # reversing log transformation\n",
    "    if transforms[0] == True:\n",
    "        train_predict = pd.Series(np.exp(train_predict), index=train_dates)\n",
    "        y_train = pd.Series(np.exp(y_train), index=train_dates)\n",
    "\n",
    "        test_predict = pd.Series(np.exp(test_predict), index=test_dates)\n",
    "        y_test = pd.Series(np.exp(y_test), index=test_dates)\n",
    "        \n",
    "    return train_predict, y_train, test_predict, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(data_series, look_back, split, transforms, lstm_params):\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # creating the training and testing datasets\n",
    "    X_train, y_train, X_test, y_test, train_dates, test_dates, scaler = create_dataset(data_series, look_back, split, transforms)\n",
    "\n",
    "    # training the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_params[0], input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=lstm_params[1], batch_size=1, verbose=lstm_params[2])\n",
    "    \n",
    "    # making predictions\n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "    \n",
    "    # inverse transforming results\n",
    "    train_predict, y_train, test_predict, y_test = \\\n",
    "    inverse_transforms(train_predict, y_train, test_predict, y_test, data_series, train_dates, test_dates, scaler)\n",
    "    \n",
    "    # plot of predictions and actual values\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    myFmt = mdates.DateFormatter('%m%/%y')\n",
    "    ax.xaxis.set_major_formatter(myFmt)\n",
    "    plt.plot(y_test)\n",
    "    plt.plot(test_predict, color='red')\n",
    "    plt.show()\n",
    "    \n",
    "    # calculating RMSE metrics\n",
    "    error = np.sqrt(mean_squared_error(train_predict, y_train))\n",
    "    print('Train RMSE: %.3f' % error)\n",
    "    error = np.sqrt(mean_squared_error(test_predict, y_test))\n",
    "    print('Test RMSE: %.3f' % error)\n",
    "    \n",
    "    return train_predict, y_train, test_predict, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_compare(original_series, predictions, data_split):\n",
    "    \n",
    "    # the train/test split used to generate the Gaussian-filtered predictions\n",
    "    size = int(len(original_series)*data_split)\n",
    "\n",
    "    # creating a plot of the original series and Gaussian-filtered predictions\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    myFmt = mdates.DateFormatter('%m%/%y')\n",
    "    ax.xaxis.set_major_formatter(myFmt)\n",
    "\n",
    "    plt.plot(original_series[size:])\n",
    "    plt.plot(predictions, color='red')\n",
    "    plt.title('Gauss-Filtered Predictions vs. Original Series')\n",
    "    plt.show()\n",
    "    \n",
    "    # calculating the RMSE between the Gaussian-filtered predictions and original dataset. \n",
    "    # the +1 exception code is required when differencing is performed, as the earliest data point can be lost\n",
    "    try:\n",
    "        error = np.sqrt(mean_squared_error(predictions, original_series[size:]))\n",
    "    except:\n",
    "        error = np.sqrt(mean_squared_error(predictions, original_series[size+1:]))\n",
    "    print('Test RMSE: %.3f' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('history.csv', parse_dates = ['date'], index_col=\"date\")\n",
    "df['price'] = df['price'].str.replace(',', '')\n",
    "df['price'] = df['price'].str.replace('$', '')\n",
    "df['price'] = df['price'].astype(float)\n",
    "df.drop(columns=['event','zid'],inplace=True)\n",
    "df = df[pd.notnull(df['price'])]\n",
    "df_monthly = df.resample('M').mean()\n",
    "df_ts = df_monthly.price\n",
    "plt.plot(df_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA Model\n",
    "data_split = 0.7\n",
    "p = 2\n",
    "d = 1\n",
    "q = 1\n",
    "params = [p, d, q]\n",
    "future_periods = 12\n",
    "log = True\n",
    "\n",
    "predictions, test, forecast = arima_model(df_ts, data_split, params, future_periods, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LSTM Model\n",
    "look_back = 1\n",
    "split = 0.7\n",
    "log = True\n",
    "difference = True\n",
    "transforms = [log, difference]\n",
    "\n",
    "nodes = 4\n",
    "epochs = 5\n",
    "verbose = 0 # 0=print no output, 1=most, 2=less, 3=least\n",
    "lstm_params = [nodes, epochs, verbose]\n",
    "\n",
    "train_predict, y_train, test_predict, y_test = lstm_model(df_ts, look_back, split, transforms, lstm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running ARIMA model with Gaussian Filter\n",
    "data_split = 0.7\n",
    "p = 0\n",
    "d = 1\n",
    "q = 1\n",
    "params = [p, d, q]\n",
    "future_periods = 12\n",
    "log = True\n",
    "\n",
    "predictions, test, forecast = arima_model(df_ts_gauss, data_split, params, future_periods, log)\n",
    "\n",
    "# comparing ARIMA model with Gaussin filter to original series\n",
    "gauss_compare(df_ts, predictions, data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running LSTM with Gaussian-filtered data\n",
    "look_back = 1\n",
    "split = 0.7\n",
    "log = True\n",
    "difference = True\n",
    "transforms = [log, difference]\n",
    "\n",
    "nodes = 4\n",
    "epochs = 10\n",
    "verbose = 0 # 0=print no output, 1=most, 2=less, 3=least\n",
    "lstm_params = [nodes, epochs, verbose]\n",
    "\n",
    "train_predict, y_train, test_predict, y_test = lstm_model(df_ts_gauss, look_back, split, transforms, lstm_params)\n",
    "\n",
    "# comparing gaussian model results to original data\n",
    "gauss_compare(df_ts, test_predict, split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
